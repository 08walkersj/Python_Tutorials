{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Downloads\n",
    "In this notebook we will speed up the downloading of files by doing them in parallel\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from urllib.request import urlretrieve\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Functions\n",
    "Here we use urlib to download files from a specified URL.\n",
    "\n",
    "The download progress hook will be displayed for each file as it downloads so that progress can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_progress_hook(count, block_size, total_size):\n",
    "    \"\"\"\n",
    "    Report hook to display a progress bar for downloading.\n",
    "    \n",
    "    :param count: Current block number being downloaded.\n",
    "    :param block_size: Size of each block (in bytes).\n",
    "    :param total_size: Total size of the file (in bytes).\n",
    "    \"\"\"\n",
    "    # Calculate percentage of the download\n",
    "    downloaded_size = count * block_size\n",
    "    percentage = min(100, downloaded_size * 100 / total_size)\n",
    "    \n",
    "    # Create a simple progress bar\n",
    "    progress_bar = f\"\\rDownloading: {percentage:.2f}% [{downloaded_size}/{total_size} bytes]\"\n",
    "    \n",
    "    # Update the progress on the same line\n",
    "    sys.stdout.write(progress_bar)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # When download is complete\n",
    "    if downloaded_size >= total_size:\n",
    "        print(\"\\nDownload complete!\")\n",
    "def download(url, file_name):\n",
    "    print(file_name)\n",
    "    return urlretrieve(url, file_name, reporthook=download_progress_hook)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create List of URLs\n",
    "We first create a list of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(fromYear, toYear + 1, 1)\n",
    "months = []\n",
    "for i in np.arange(1, 13, 1):\n",
    "    months.append('%02i' % i)\n",
    "urls= []\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        if not ((y == years[0]) & (int(m) < monthFirstYear)) | ((y == years[-1]) & (int(m) > monthLastYear)):\n",
    "            urls.append('https://cdaweb.gsfc.nasa.gov/sp_phys/data/omni/hro_1min/' + str(y) + \\\n",
    "                        '/omni_hro_1min_' + str(y) + str(m) + '01_v01.cdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Download\n",
    "By using Parallel and delayed we are able to queue each file download and then perform them on multiple cores at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "download_args = [(url, './omni_tempfiles/'+url.split('/')[-1]) for url in urls]\n",
    "Parallel(n_jobs=12, backend='threading')(delayed(download)(*args) for args in download_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative\n",
    "Here is an alternative using multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "p= Pool(8)\n",
    "p.map(download, urls)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
